# When to use each MCP tool: decision guide

> **Audience:** Both humans (documentation) and coding agents (instructions)
> **Purpose:** Optimal tool selection to maximize value, avoid rate limits, and minimize waste

---

## Table of contents

- [Quick Reference: Tool Usage Hierarchy](#quick-reference-tool-usage-hierarchy)
- [Detailed Tool Profiles](#detailed-tool-profiles)
- [Decision Trees by Task Type](#decision-trees-by-task-type)
- [Rate Limit Management](#rate-limit-management)
- [Special Cases & Gotchas](#special-cases--gotchas)

---

## Quick reference: tool usage hierarchy

### Web browsing/researching/fetching tools (use following prescribed priorities)

**Tier 1: Primary Tools (Use First)**

1.  **Sourcegraph MCP** - Code search across public repos
2.  **Tavily MCP** - Web research with citations (1000 credits/month)
3.  **Context7 MCP** - API documentation and examples

**Tier 2: Specialized Tools (Conditional Use)**

4.  **Brave MCP** - Privacy-focused search (2000 queries/month)
5.  **Exa MCP** - Neural/semantic search optimized for AI ($10 one-time credit)
6.  **Firecrawl MCP** - Advanced crawling (**CRITICAL: 500 lifetime limit**)

**Tier 3: Fallback Tools (Last Resort)**

7.  **Fetch MCP** - Simple URL fetching (no rate limits)

### Memory & coding tools (use as needed)

**Memory & Knowledge:**

-   **Qdrant MCP** - Semantic memory layer (vector search, find by meaning, no rate limits)
-   **Memory MCP** - Knowledge graph (entities/relations, structured memory, no rate limits)

**Code Analysis & Manipulation:**

-   **Serena MCP** - Semantic code navigation/refactoring (symbol-level operations)
-   **Semgrep MCP** - Security/bug scanning (pattern-based analysis)
-   **Filesystem MCP** - File operations (read/write/edit)
-   **Git MCP** - Git operations (status/diff/commit/etc.)

---

## Detailed tool profiles

### Web research & search tools

#### Sourcegraph MCP â­ **[PRIMARY FOR CODE]**

**What it does:**

-   "Google for code" - searches across public GitHub repos
-   Powerful filters: regex, language, file path, branch
-   Guided search prompts (natural language â†’ precise queries)
-   Returns exact code snippets with line numbers

**When to use:**

-   Finding code examples/patterns across repos
-   Researching how libraries/APIs are used in practice
-   Discovering implementations of specific algorithms
-   Learning from real-world code

**Rate limits:** None apparent (free tier for public repos)

**Why use first:** Purpose-built for code search with no strict limits

---

#### Tavily MCP â­ **[PRIMARY FOR WEB]**

**What it does:**

-   Web search, extract, map, and crawl
-   **Includes citations** (critical for credibility)
-   Handles news, general info, current events

**When to use:**

-   General web research
-   Finding current information
-   Getting cited sources for claims
-   Extracting content from known URLs
-   Mapping site structure

**Rate limits:** 1000 API credits/month (resets on 1st)

-   Basic search: ~1-5 credits
-   Extract: varies by complexity
-   See [full credit costs](https://docs.tavily.com/documentation/api-credits#api-credits-costs)

**Why use second:** Best balance of features and generous limits

---

#### Context7 MCP â­ **[PRIMARY FOR DOCS]**

**What it does:**

-   Fetches up-to-date, version-specific API documentation
-   Includes code examples from official docs
-   Works with public repos only

**When to use:**

-   Learning a new library/framework
-   Checking current API syntax
-   Getting official usage examples
-   Understanding library capabilities

**Rate limits:** Free tier, public repos only

**Why use third:** Specialized for documentation, no apparent hard limits

---

#### Brave MCP **[SECONDARY SEARCH]**

**What it does:**

-   Privacy-focused search engine
-   Web, local, news, image, video search
-   No tracking or profiling

**When to use:**

-   Tavily credits exhausted
-   Need privacy-focused results
-   Basic web search without advanced features

**Rate limits:** 2000 queries/month (basic web search only on free tier)

**Why use here:** Good fallback when Tavily exhausted, but limited to basic search

---

#### Exa MCP **[SPECIALIZED SEARCH]**

**What it does:**

-   Neural search optimized for LLMs
-   Better semantic understanding than keyword search
-   AI-native result formatting
-   Superior for research and knowledge discovery

**When to use:**

-   Need semantic/conceptual search (not just keywords)
-   Research requiring deep understanding
-   Tavily and Brave don't find what you need
-   Task justifies using limited credits

**Rate limits:** $10 one-time credit (new account needed after exhaustion)

**Why use conditionally:** Limited credits, but excellent semantic capabilities

---

#### Firecrawl MCP âš ï¸ **[LAST RESORT]**

**What it does:**

-   Advanced website crawling/scraping
-   Batch operations
-   Deep extraction and mapping
-   "Better" web search

**When to use:**

-   **ONLY** when other tools cannot handle the task
-   Need deep multi-page crawling
-   Require batch processing
-   Complex extraction that Tavily/Fetch can't do

**Rate limits:**

-   10 `/scrape` calls/min
-   1 `/crawl` call/min
-   **CRITICAL: 500 lifetime limit before new account required**

**Why use last:** Severe lifetime limit - reserve for tasks requiring unique capabilities

---

#### Fetch MCP **[SIMPLE FALLBACK]**

**What it does:**

-   Basic HTTP/HTTPS URL fetching
-   Converts HTML to Markdown
-   Optional raw HTML
-   Chunk reading via start_index

**When to use:**

-   Simple one-off URL fetch
-   Don't need search/crawl/extraction
-   All other tools exhausted or overkill

**Rate limits:** None

**Limitations:**

-   **Does NOT support fetching directly from github.com** (fetch from `raw.githubusercontent.com` instead, or use `gh` CLI)

**Why use last:** No advanced features, but reliable and unlimited

---

### Memory & knowledge tools

#### Qdrant MCP â­ **[PRIMARY FOR SEMANTIC MEMORY]**

**What it does:**

-   Vector-based semantic memory layer using Qdrant database
-   Stores information with embeddings for semantic (meaning-based) retrieval
-   Uses FastEmbed models (default: sentence-transformers/all-MiniLM-L6-v2)
-   Can run locally or connect to cloud/remote Qdrant instances
-   Supports optional structured metadata alongside text

**Tools available:**

1.  `qdrant-store` - Store information with optional metadata
2.  `qdrant-find` - Retrieve semantically similar information by query

**When to use:**

-   Storing code snippets, notes, or links for later retrieval
-   Building a personal knowledge base across sessions
-   Need to find information by *meaning* rather than exact keywords
-   Want to search by concept or similarity (e.g., "authentication patterns" finds OAuth, JWT, etc.)
-   Storing learned insights from previous conversations
-   Building a semantic search layer for your own data

**When NOT to use:**

-   Need to track explicit relationships between items â†’ Use Memory MCP instead
-   Need structured graph queries â†’ Use Memory MCP instead
-   Simple keyword search is sufficient â†’ Use grep/filesystem tools
-   One-time lookup (not worth storing) â†’ Use web search tools directly

**Rate limits:** None (local Docker container or self-hosted)

**Best practices:**

-   Store atomic pieces of information (one concept per store)
-   Use metadata field for structure (e.g., `{"type": "code", "language": "python"}`)
-   Descriptive text helps retrieval (include context, not just code)
-   Good for: code patterns, solutions to problems, useful links, learned facts
-   Works great with Cursor/Windsurf for code snippet libraries

**Example use cases:**

-   "Store this React hook pattern for reuse later" â†’ retrieves by describing what you need
-   Building a personal StackOverflow of solved problems
-   Remembering API patterns across different projects
-   Semantic code snippet search in your IDE

**Why use:** Best tool for "find things similar to X" - works like a persistent, intelligent search over your saved knowledge

---

#### Memory MCP â­ **[PRIMARY FOR KNOWLEDGE GRAPHS]**

**What it does:**

-   Persistent knowledge graph with entities, relations, and observations
-   Tracks explicit relationships between concepts/people/things
-   Stores structured information in local JSONL file
-   Maintains context and facts across sessions
-   Official MCP implementation by Anthropic

**Tools available:**

1.  `create_entities` - Create nodes in the graph (people, orgs, events, concepts)
2.  `create_relations` - Define directed relationships between entities (in active voice)
3.  `add_observations` - Add facts/notes to existing entities
4.  `delete_entities` - Remove entities and their relations
5.  `delete_observations` - Remove specific facts from entities
6.  `delete_relations` - Remove specific relationships
7.  `read_graph` - Read the entire knowledge graph
8.  `search_nodes` - Search entities by name/type/observation content
9.  `open_nodes` - Retrieve specific entities by name

**When to use:**

-   Need to track *who* relates to *what* and *how*
-   Building a structured knowledge base with explicit relationships
-   Tracking project context (people, components, dependencies)
-   Maintaining facts about users/preferences/history
-   Creating a personal CRM or project memory
-   Need to query relationships (e.g., "who works at company X?")
-   Storing learnings with clear connections between concepts

**When NOT to use:**

-   Need semantic/similarity search â†’ Use Qdrant MCP instead
-   Relationships aren't important, just storage â†’ Use Qdrant MCP instead
-   Simple note-taking without structure â†’ Use filesystem or Qdrant
-   Temporary context (single session) â†’ Just keep in conversation context

**Rate limits:** None (local JSONL file storage)

**Best practices:**

-   Entities: Use clear, unique names (e.g., "John_Smith", "ProjectX")
-   Relations: Always use active voice (e.g., "works_at", "depends_on")
-   Observations: Keep atomic (one fact per observation)
-   Entity types: Use consistent categorization (e.g., "person", "company", "project")
-   Relations are directed: order matters (from â†’ to)

**Example structure:**

```
Entity: John_Smith (type: person)
    Observations: ["Speaks Spanish", "Prefers async communication"]
    Relations: John_Smith --works_at--> Anthropic
               John_Smith --contributes_to--> ProjectX

Entity: Anthropic (type: company)
    Observations: ["AI safety research", "Based in San Francisco"]
```

**Example use cases:**

-   Personal memory: Remember user preferences, context, history
-   Project documentation: Track components, dependencies, who owns what
-   Relationship mapping: Social/professional network graphs
-   Learning journal: Connect concepts, topics, resources with explicit links
-   Code understanding: Map relationships between modules, functions, data flows

**Why use:** Best tool for "X relates to Y" - maintains structured knowledge with queryable relationships

---

### Qdrant vs memory: quick decision guide

**Use Qdrant when:**

-   "Find things similar to this concept"
-   Semantic search is the main access pattern
-   Relationships between items aren't critical
-   Building a retrieval/search system

**Use Memory when:**

-   "Show me what relates to X"
-   Explicit relationships matter
-   Need structured graph queries
-   Building a knowledge/context management system

**Use both when:**

-   Complex knowledge base needs both similarity search AND relationship tracking
-   E.g., Qdrant for code snippets, Memory for tracking which projects use which patterns

---

### Code analysis & manipulation tools

#### Serena MCP â­ **[PRIMARY FOR CODE EDITING]**

**What it does:**

-   Language-server-powered semantic code navigation
-   IDE-grade symbol search (find_symbol, find_referencing_symbols)
-   Structural edits (rename, insert, replace at symbol level)
-   20+ languages supported

**When to use:**

-   Need semantic understanding of code (not just text)
-   Refactoring operations
-   Finding all references to a symbol
-   IDE-level code intelligence

**Rate limits:** None (local server)

**Why use:** Works at semantic level vs. whole-file operations

---

#### Semgrep MCP

**What it does:**

-   AST-aware security/bug/anti-pattern scanning
-   Pattern-based rules (built-in or custom)
-   Autofix suggestions
-   Local scanning (code never leaves machine)

**When to use:**

-   Security audits
-   Finding bugs/anti-patterns
-   Code quality checks
-   Custom rule enforcement

**Rate limits:** None (free community edition, local server)

---

#### Filesystem MCP

**What it does:** File operations (read/write/edit/create/list/delete/move)

**When to use:**
- Batch reading 10+ files (`read_multiple_files` - 30-60% token savings vs multiple Read calls)
- Analyzing project structures / directory trees (`directory_tree` returns JSON)

**When NOT to use:** Built-ins (Read/Write/Edit/Glob/Grep) already provide structured operations for 1-5 files and basic CRUD. Using the MCP in these cases simply adds overhead without benefit.

**Rate limits:** None (local)

---

#### Git MCP

**What it does:** All Git operations (status/diff/log/add/commit/branch/etc.)

**When to use:** Any Git-related task

**Rate limits:** None (local)

**Note:** Parent agent must run at repo root

---

## Decision trees by task type

### Finding code examples

```
START
    â†“
Need code from public repos?
    â”œâ”€ YES â†’ Use Sourcegraph MCP (no rate limits)
    â””â”€ NO  â†’ Need GitHub-specific?
        â”œâ”€ YES â†’ Use gh CLI or raw.githubusercontent.com via Fetch
        â””â”€ NO  â†’ Context7 for docs/examples from official sources
```

### Web research & information gathering

```
START
    â†“
What type of information?
    â”œâ”€ API docs/library info â†’ Context7 MCP
    â”œâ”€ Current events/general web â†’ Tavily MCP
    â”œâ”€ Semantic/conceptual search â†’ Check Tavily first
    â”‚                                â†“ If insufficient
    â”‚                                Exa MCP (mind credits!)
    â””â”€ Simple URL content â†’ Fetch MCP
```

### Website crawling/scraping

```
START
    â†“
Single URL or simple extraction?
    â”œâ”€ YES â†’ Tavily extract or Fetch MCP
    â””â”€ NO  â†’ Multiple pages/complex?
        â†“
        Try Tavily search/extract first
        â†“ Still need more?
        â†“
        Check if worth 1-10 Firecrawl credits
        â”œâ”€ YES â†’ Use Firecrawl (track usage!)
        â””â”€ NO  â†’ Rethink approach or use Fetch iteratively
```

### Code manipulation

```
START
    â†“
Need semantic understanding?
    â”œâ”€ YES â†’ Serena MCP (symbol-level operations)
    â””â”€ NO  â†’ Simple file edits?
        â”œâ”€ YES â†’ Filesystem MCP
        â””â”€ NO  â†’ Security/bug scan â†’ Semgrep MCP
```

### Memory & knowledge storage

```
START
    â†“
Need to store/retrieve information across sessions?
    â”œâ”€ NO  â†’ Keep in conversation context
    â””â”€ YES â†’ What's the primary access pattern?
        â†“
        Do relationships between items matter?
        â”œâ”€ NO  â†’ Need similarity/semantic search?
        â”‚        â”œâ”€ YES â†’ Qdrant MCP
        â”‚        â”‚        (find by meaning: "auth patterns" â†’ OAuth/JWT/etc.)
        â”‚        â””â”€ NO  â†’ Simple storage â†’ Filesystem or notes
        â”‚
        â””â”€ YES â†’ Need explicit relationships?
            â”œâ”€ YES â†’ Memory MCP
            â”‚        (track X relates to Y: person â†’ works_at â†’ company)
            â””â”€ NO  â†’ Qdrant MCP sufficient

Special case: Complex knowledge base?
    â†’ Use BOTH:
        â€¢ Qdrant: Store searchable content
        â€¢ Memory: Track relationships between content

Example: Code snippet library
    â†’ Qdrant: Store snippets, find by description
    + Memory: Track which projects/patterns use which snippets
```

---

## Rate limit management

### Critical limits to track

| Tool | Limit Type | Amount | Reset | Severity |
|------|-----------|---------|-------|----------|
| Firecrawl | One-time credit | 500 total | Never | ğŸŸ  HIGH |
| Exa | One-time credit | $10 | Never | ğŸŸ  HIGH |
| Tavily | Monthly | 1000 credits | 1st of month | ğŸŸ¡ MEDIUM |
| Brave | Monthly | 2000 queries | Monthly | ğŸŸ¡ MEDIUM |
| Sourcegraph | None | âˆ | N/A | ğŸŸ¢ SAFE |
| Fetch | None | âˆ | N/A | ğŸŸ¢ SAFE |

### Strategies

1.  **Always exhaust unlimited tools first** (Sourcegraph, Fetch)
2.  **Use monthly-reset tools before one-time credits** (Tavily/Brave before Exa)
3.  **Treat Firecrawl as emergency-only** - every use is permanent
4.  **Track Firecrawl usage manually** - no built-in counter
5.  **Front-load Tavily early in month** - will reset on 1st

### Cost-benefit analysis before using limited tools

**Before using Firecrawl, ask:**

-   Can Tavily do this? (Usually yes for search/extract)
-   Can Fetch do this iteratively? (Usually yes for known URLs)
-   Is this worth 1-10 permanent credits?
-   Is this a one-time need or recurring?

**Before using Exa, ask:**

-   Did Tavily fail to find it?
-   Do I need semantic search specifically?
-   Is this worth $X from one-time credit?

---

## Special cases & gotchas

### GitHub content

âŒ **DON'T:** Use Fetch MCP on github.com URLs (not supported)

âœ… **DO:** Use one of these:

1.  **Best:** `raw.githubusercontent.com/<user>/<repo>/<branch>/<file>` via Fetch
2.  **Also good:** `gh` CLI locally
3.  **For search:** Sourcegraph MCP
4.  **For analysis:** Clone locally + Git MCP + Serena MCP

### Documentation lookup

**Use this priority:**

1.  Context7 (official docs, version-specific)
2.  Tavily search (general web docs, tutorials)
3.  Sourcegraph (real-world usage examples)

### Multi-page content extraction

**Don't default to Firecrawl! Try this sequence:**

1.  Tavily search to find relevant pages
2.  Tavily extract on specific URLs
3.  If still insufficient, Fetch iteratively on known URLs
4.  **Last resort:** Firecrawl crawl (costs 1+ credits permanently)

### Memory & knowledge storage

**Memory MCP Best Practices:**

âŒ **DON'T:**

-   Use passive voice for relations ("is_managed_by" â†’ use "manages")
-   Create duplicate entities (check with `search_nodes` first)
-   Store multiple facts in one observation
-   Use complex entity names with spaces/special chars

âœ… **DO:**

-   Use active voice relations: "John --works_at--> Company" (not "Company --employs--> John")
-   Use underscores in names: "John_Smith", not "John Smith"
-   Keep observations atomic: ["Speaks Spanish", "Graduated 2019"] (not ["Speaks Spanish and graduated in 2019"])
-   Use consistent entity types across the graph

**Qdrant vs Memory Decision:**

| Scenario | Use Qdrant | Use Memory | Use Both |
|----------|-----------|------------|----------|
| Store code snippets for "find similar" | âœ… | âŒ | Optional |
| Track who created what code | âŒ | âœ… | Recommended |
| Personal knowledge base | âœ… | âŒ | Optional |
| Project relationship map | âŒ | âœ… | N/A |
| Searchable docs + author tracking | âœ… | âœ… | âœ… |

**Data Persistence:**

-   **Qdrant**: Data in Docker volume (survives restarts) OR cloud (persistent)
-   **Memory**: JSONL file (location: `MEMORY_FILE_PATH` or default in server dir)
-   Both require explicit deletion - data persists across sessions

### When multiple tools can work

**Default to this order:**

1.  Unlimited tools (Sourcegraph, Fetch)
2.  Monthly-reset tools (Tavily, Brave)
3.  One-time credit tools (Exa)
4.  Lifetime-limited tools (Firecrawl - **avoid unless critical**)

---

## Summary: golden rules

### Search & research
1.  **Sourcegraph first for code**, Tavily first for web
2.  **Never use Firecrawl without checking if Tavily/Fetch can do it**
3.  **Track Firecrawl usage manually** - 500 limit is forever
4.  **Exa is powerful but limited** - use only when semantic search is critical
5.  **Fetch is unlimited** - use liberally for simple fetches
6.  **Context7 for official docs**, Sourcegraph for real examples
7.  **Front-load Tavily early each month** before credits run out

### Memory & knowledge
8.  **Qdrant for "find similar"**, Memory for "X relates to Y"
9.  **Both memory tools have no rate limits** - use freely for persistent storage
10. **Qdrant needs Docker OR cloud**, Memory works out of the box
11. **Memory relations in active voice** - "works_at" not "is_employed_by"
12. **Data persists across sessions** - remember to clean up when done

---

## Quick decision flowchart

```
Need to accomplish task
    â†“
Is it code-related?
    â”œâ”€ YES â†’ Finding examples? â†’ Sourcegraph
    â”‚        â†“
    â”‚        Need docs? â†’ Context7
    â”‚        â†“
    â”‚        Editing/refactoring? â†’ Serena
    â”‚        â†“
    â”‚        Security scan? â†’ Semgrep
    â”‚
    â””â”€ NO  â†’ Is it web/research?
        â”œâ”€ YES â†’ General info? â†’ Tavily
        â”‚        â†“
        â”‚        Simple URL? â†’ Fetch
        â”‚        â†“
        â”‚        Need semantic search? â†’ Try Tavily first, then Exa
        â”‚        â†“
        â”‚        Complex crawl? â†’ Try Tavily, then consider Firecrawl
        â”‚
        â””â”€ NO  â†’ Memory storage? â†’ Qdrant (semantic) or Memory (graph)
            â†“
            Files? â†’ Filesystem
            â†“
            Git? â†’ Git MCP
```

---

*Last updated: 2025-10-22*
